{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "We have a dataset containing excerpts of different pasaages and target column indicating the difficult of the passage i.e the reading ease. We need to predict the reading ease of unknown passages in test data.\n",
    "\n",
    "## Approach Followed:\n",
    "Here we follow below steps to solve this problem -\n",
    "* Combine the train and test excerpts to preprocess them at once\n",
    "* Apply preprocessing to these texts\n",
    "* Prepare data for LSTM model by creating padded sequences of same length\n",
    "* Use Google Word2Vec pretrained embeddings to create an embedding matrix for the LSTM input layer\n",
    "* Run LSTM model on train data, keeping test split as validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T12:56:56.899853Z",
     "iopub.status.busy": "2021-06-22T12:56:56.899290Z",
     "iopub.status.idle": "2021-06-22T12:56:57.035041Z",
     "shell.execute_reply": "2021-06-22T12:56:57.033668Z",
     "shell.execute_reply.started": "2021-06-22T12:56:56.899740Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2834, 6)\n",
      "(7, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>url_legal</th>\n",
       "      <th>license</th>\n",
       "      <th>excerpt</th>\n",
       "      <th>target</th>\n",
       "      <th>standard_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c12129c31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>When the young people returned to the ballroom...</td>\n",
       "      <td>-0.340259</td>\n",
       "      <td>0.464009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85aa80a4c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All through dinner time, Mrs. Fayre was somewh...</td>\n",
       "      <td>-0.315372</td>\n",
       "      <td>0.480805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b69ac6792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Roger had predicted, the snow departed as q...</td>\n",
       "      <td>-0.580118</td>\n",
       "      <td>0.476676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dd1000b26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>And outside before the palace a great garden w...</td>\n",
       "      <td>-1.054013</td>\n",
       "      <td>0.450007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37c1b32fb</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Once upon a time there were Three Bears who li...</td>\n",
       "      <td>0.247197</td>\n",
       "      <td>0.510845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id url_legal license  \\\n",
       "0  c12129c31       NaN     NaN   \n",
       "1  85aa80a4c       NaN     NaN   \n",
       "2  b69ac6792       NaN     NaN   \n",
       "3  dd1000b26       NaN     NaN   \n",
       "4  37c1b32fb       NaN     NaN   \n",
       "\n",
       "                                             excerpt    target  standard_error  \n",
       "0  When the young people returned to the ballroom... -0.340259        0.464009  \n",
       "1  All through dinner time, Mrs. Fayre was somewh... -0.315372        0.480805  \n",
       "2  As Roger had predicted, the snow departed as q... -0.580118        0.476676  \n",
       "3  And outside before the palace a great garden w... -1.054013        0.450007  \n",
       "4  Once upon a time there were Three Bears who li...  0.247197        0.510845  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "train_df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\n",
    "print(train_df.shape)\n",
    "print(test_df.shape)\n",
    "train_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean the excerpt text\n",
    "1. Remove all characters apart from alphabets\n",
    "2. Lowercase the text\n",
    "3. Lemmatize the text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:13:36.762989Z",
     "iopub.status.busy": "2021-06-22T09:13:36.762480Z",
     "iopub.status.idle": "2021-06-22T09:13:36.768972Z",
     "shell.execute_reply": "2021-06-22T09:13:36.767933Z",
     "shell.execute_reply.started": "2021-06-22T09:13:36.762953Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "def preprocess(text):\n",
    "    text = re.sub('[^a-zA-Z]', ' ', text)\n",
    "    text = text.lower()\n",
    "    words = text.split()\n",
    "    words = [lemma.lemmatize(word) for word in words if word not in stopwords.words('english')]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:13:36.770991Z",
     "iopub.status.busy": "2021-06-22T09:13:36.770533Z",
     "iopub.status.idle": "2021-06-22T09:14:44.110614Z",
     "shell.execute_reply": "2021-06-22T09:14:44.109327Z",
     "shell.execute_reply.started": "2021-06-22T09:13:36.770943Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [young, people, returned, ballroom, presented,...\n",
       "1    [dinner, time, mr, fayre, somewhat, silent, ey...\n",
       "2    [roger, predicted, snow, departed, quickly, ca...\n",
       "3    [outside, palace, great, garden, walled, round...\n",
       "4    [upon, time, three, bear, lived, together, hou...\n",
       "Name: excerpt, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "excerpt_text = train_df['excerpt'].append(test_df['excerpt'])\n",
    "excerpt_text = excerpt_text.apply(lambda x: preprocess(x))\n",
    "excerpt_text.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Keras Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data for Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:14:44.112372Z",
     "iopub.status.busy": "2021-06-22T09:14:44.112009Z",
     "iopub.status.idle": "2021-06-22T09:14:46.093356Z",
     "shell.execute_reply": "2021-06-22T09:14:46.092011Z",
     "shell.execute_reply.started": "2021-06-22T09:14:44.112339Z"
    }
   },
   "outputs": [],
   "source": [
    "# Tokenize the excerpt text data. This will assign unique integer to every unique word in excerpt text data\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(excerpt_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:14:46.095131Z",
     "iopub.status.busy": "2021-06-22T09:14:46.094804Z",
     "iopub.status.idle": "2021-06-22T09:14:46.100874Z",
     "shell.execute_reply": "2021-06-22T09:14:46.099640Z",
     "shell.execute_reply.started": "2021-06-22T09:14:46.095098Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size is 22597\n"
     ]
    }
   ],
   "source": [
    "# Get total words in excerpt text. This will be used to create the embedding matrix of shape (vocab_size, Dimension(word_embedding))\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "print(\"Vocabulary size is {}\".format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:14:46.105094Z",
     "iopub.status.busy": "2021-06-22T09:14:46.104618Z",
     "iopub.status.idle": "2021-06-22T09:14:46.260308Z",
     "shell.execute_reply": "2021-06-22T09:14:46.259000Z",
     "shell.execute_reply.started": "2021-06-22T09:14:46.105046Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2841 excerpts and 2841 sequences\n",
      "Min sequence length is 52\n",
      "Max sequence length is 135\n"
     ]
    }
   ],
   "source": [
    "sequences = tokenizer.texts_to_sequences(excerpt_text)\n",
    "print(f\"There are {excerpt_text.shape[0]} excerpts and {len(sequences)} sequences\")\n",
    "print(f\"Min sequence length is {min([len(s) for s in sequences])}\")\n",
    "print(f\"Max sequence length is {max([len(s) for s in sequences])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:14:46.263444Z",
     "iopub.status.busy": "2021-06-22T09:14:46.262966Z",
     "iopub.status.idle": "2021-06-22T09:14:46.350792Z",
     "shell.execute_reply": "2021-06-22T09:14:46.349737Z",
     "shell.execute_reply.started": "2021-06-22T09:14:46.263390Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min sequence length is 135\n",
      "Max sequence length is 135\n",
      "Shape of sequences is (2841, 135)\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "sequences = pad_sequences(sequences, padding='post')\n",
    "print(f\"Min sequence length is {min([len(s) for s in sequences])}\")\n",
    "print(f\"Max sequence length is {max([len(s) for s in sequences])}\")\n",
    "print(f\"Shape of sequences is {sequences.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Google Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:14:46.353222Z",
     "iopub.status.busy": "2021-06-22T09:14:46.352778Z",
     "iopub.status.idle": "2021-06-22T09:15:33.103100Z",
     "shell.execute_reply": "2021-06-22T09:15:33.102057Z",
     "shell.execute_reply.started": "2021-06-22T09:14:46.353175Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding = gensim.models.KeyedVectors.load_word2vec_format('../input/word2vec-google/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:15:33.107521Z",
     "iopub.status.busy": "2021-06-22T09:15:33.107169Z",
     "iopub.status.idle": "2021-06-22T09:15:33.247969Z",
     "shell.execute_reply": "2021-06-22T09:15:33.246914Z",
     "shell.execute_reply.started": "2021-06-22T09:15:33.107487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22597, 300)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((vocab_size, 300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    try:\n",
    "        embedding_vector = embedding.get_vector(word)\n",
    "    except:\n",
    "        embedding_vector = np.zeros((300,))\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:24:34.903112Z",
     "iopub.status.busy": "2021-06-22T09:24:34.902718Z",
     "iopub.status.idle": "2021-06-22T09:24:35.233091Z",
     "shell.execute_reply": "2021-06-22T09:24:35.231905Z",
     "shell.execute_reply.started": "2021-06-22T09:24:34.903077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 135, 300)          6779100   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 6,939,601\n",
      "Trainable params: 160,501\n",
      "Non-trainable params: 6,779,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, Dense, LSTM\n",
    "from keras.initializers import Constant\n",
    "\n",
    "model = keras.Sequential()\n",
    "model.add(Embedding(vocab_size, 300, embeddings_initializer=Constant(embedding_matrix), input_length=135, trainable=False))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mean_squared_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:15:33.699937Z",
     "iopub.status.busy": "2021-06-22T09:15:33.699646Z",
     "iopub.status.idle": "2021-06-22T09:15:33.709717Z",
     "shell.execute_reply": "2021-06-22T09:15:33.708490Z",
     "shell.execute_reply.started": "2021-06-22T09:15:33.699907Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2125, 135)\n",
      "(2125,)\n",
      "(709, 135)\n",
      "(709,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "target = train_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(sequences).head(train_df.shape[0]), target)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:24:37.449408Z",
     "iopub.status.busy": "2021-06-22T09:24:37.448896Z",
     "iopub.status.idle": "2021-06-22T09:27:42.729070Z",
     "shell.execute_reply": "2021-06-22T09:27:42.728047Z",
     "shell.execute_reply.started": "2021-06-22T09:24:37.449376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch 1/15\n",
      "133/133 - 15s - loss: 0.9485 - mean_squared_error: 0.9485 - val_loss: 0.8839 - val_mean_squared_error: 0.8839\n",
      "Epoch 2/15\n",
      "133/133 - 12s - loss: 0.7402 - mean_squared_error: 0.7402 - val_loss: 0.7240 - val_mean_squared_error: 0.7240\n",
      "Epoch 3/15\n",
      "133/133 - 12s - loss: 0.8970 - mean_squared_error: 0.8970 - val_loss: 0.9136 - val_mean_squared_error: 0.9136\n",
      "Epoch 4/15\n",
      "133/133 - 12s - loss: 0.9655 - mean_squared_error: 0.9655 - val_loss: 1.0076 - val_mean_squared_error: 1.0076\n",
      "Epoch 5/15\n",
      "133/133 - 12s - loss: 0.9887 - mean_squared_error: 0.9887 - val_loss: 0.9937 - val_mean_squared_error: 0.9937\n",
      "Epoch 6/15\n",
      "133/133 - 12s - loss: 0.9879 - mean_squared_error: 0.9879 - val_loss: 1.0007 - val_mean_squared_error: 1.0007\n",
      "Epoch 7/15\n",
      "133/133 - 12s - loss: 0.9875 - mean_squared_error: 0.9875 - val_loss: 1.0096 - val_mean_squared_error: 1.0096\n",
      "Epoch 8/15\n",
      "133/133 - 12s - loss: 0.9882 - mean_squared_error: 0.9882 - val_loss: 1.0000 - val_mean_squared_error: 1.0000\n",
      "Epoch 9/15\n",
      "133/133 - 12s - loss: 0.9874 - mean_squared_error: 0.9874 - val_loss: 1.0283 - val_mean_squared_error: 1.0283\n",
      "Epoch 10/15\n",
      "133/133 - 12s - loss: 0.9926 - mean_squared_error: 0.9926 - val_loss: 0.9769 - val_mean_squared_error: 0.9769\n",
      "Epoch 11/15\n",
      "133/133 - 12s - loss: 0.8595 - mean_squared_error: 0.8595 - val_loss: 0.7745 - val_mean_squared_error: 0.7745\n",
      "Epoch 12/15\n",
      "133/133 - 12s - loss: 0.7153 - mean_squared_error: 0.7153 - val_loss: 0.6753 - val_mean_squared_error: 0.6753\n",
      "Epoch 13/15\n",
      "133/133 - 12s - loss: 0.6022 - mean_squared_error: 0.6022 - val_loss: 0.6070 - val_mean_squared_error: 0.6070\n",
      "Epoch 14/15\n",
      "133/133 - 12s - loss: 0.5262 - mean_squared_error: 0.5262 - val_loss: 0.5409 - val_mean_squared_error: 0.5409\n",
      "Epoch 15/15\n",
      "133/133 - 12s - loss: 0.4695 - mean_squared_error: 0.4695 - val_loss: 0.5079 - val_mean_squared_error: 0.5079\n"
     ]
    }
   ],
   "source": [
    "print(\"Training...\")\n",
    "history = model.fit(x=X_train, y=y_train, batch_size=16, epochs=15, validation_data=(X_test, y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:29:14.139252Z",
     "iopub.status.busy": "2021-06-22T09:29:14.138830Z",
     "iopub.status.idle": "2021-06-22T09:29:15.748852Z",
     "shell.execute_reply": "2021-06-22T09:29:15.747790Z",
     "shell.execute_reply.started": "2021-06-22T09:29:14.139217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7126405569416674"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "y_pred = model.predict(X_test)\n",
    "np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:35:18.541482Z",
     "iopub.status.busy": "2021-06-22T09:35:18.541065Z",
     "iopub.status.idle": "2021-06-22T09:35:18.643529Z",
     "shell.execute_reply": "2021-06-22T09:35:18.642362Z",
     "shell.execute_reply.started": "2021-06-22T09:35:18.541430Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f722661</td>\n",
       "      <td>-0.976133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f0953f0a5</td>\n",
       "      <td>-0.757631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0df072751</td>\n",
       "      <td>-1.031678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04caf4e0c</td>\n",
       "      <td>-1.752487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0e63f8bea</td>\n",
       "      <td>-2.273083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12537fe78</td>\n",
       "      <td>-1.096488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>965e592c0</td>\n",
       "      <td>0.050508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    target\n",
       "0  c0f722661 -0.976133\n",
       "1  f0953f0a5 -0.757631\n",
       "2  0df072751 -1.031678\n",
       "3  04caf4e0c -1.752487\n",
       "4  0e63f8bea -2.273083\n",
       "5  12537fe78 -1.096488\n",
       "6  965e592c0  0.050508"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(pd.DataFrame(sequences).tail(test_df.shape[0])).reshape(test_df.shape[0])\n",
    "sample_submission = pd.DataFrame(list(zip(test_df['id'], pred)), columns=['id', 'target'])\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-22T09:35:26.525332Z",
     "iopub.status.busy": "2021-06-22T09:35:26.524943Z",
     "iopub.status.idle": "2021-06-22T09:35:26.535564Z",
     "shell.execute_reply": "2021-06-22T09:35:26.534455Z",
     "shell.execute_reply.started": "2021-06-22T09:35:26.525298Z"
    }
   },
   "outputs": [],
   "source": [
    "sample_submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
